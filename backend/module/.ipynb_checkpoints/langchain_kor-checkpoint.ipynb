{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import openai\n",
    "# openai.Model.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read OPENAI API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from kor import create_extraction_chain, Object, Text, Number\n",
    "\n",
    "with open(\"API_KEY\", \"r\", encoding=\"utf-8\") as f:\n",
    "    key = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Schema\n",
    "create schema for some category of pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Object(\n",
    "    id=\"personal_info\",\n",
    "    description=\"Personal information about a given person.\",\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id=\"first_name\",\n",
    "            description=\"The first name of the person\",\n",
    "            examples=[(\"John Smith went to the store\", \"John\")],\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"last_name\",\n",
    "            description=\"The last name of the person\",\n",
    "            examples=[(\"John Smith went to the store\", \"Smith\")],\n",
    "        ),\n",
    "        Number(\n",
    "            id=\"age\",\n",
    "            description=\"The age of the person in years.\",\n",
    "            examples=[(\"23 years old\", \"23\"), (\"I turned three on sunday\", \"3\")],\n",
    "        ),\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"John Smith was 23 years old. He was very tall. He knew Jane Doe. She was 5 years old.\",\n",
    "            [\n",
    "                {\"first_name\": \"John\", \"last_name\": \"Smith\", \"age\": 23},\n",
    "                {\"first_name\": \"Jane\", \"last_name\": \"Doe\", \"age\": 5},\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    many=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"Please output the extracted information in JSON format. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.\n",
    "\n",
    "{text} \"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generate LengChain\n",
    "Instantiate a langchain LLM and create a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    top_p=1.0,     \n",
    "    openai_api_key=key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract\n",
    "With a chain and a schema defined, weâ€™re ready to extract data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_extraction_chain(llm, schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for HumanMessage\ncontent\n  str type expected (type=type_error.str)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_string())\n",
      "File \u001b[1;32m~\\OneDrive\\School\\lab\\Data Extraction from PDF\\code\\pdf-extraction\\venv2\\lib\\site-packages\\kor\\prompts.py:82\u001b[0m, in \u001b[0;36mExtractionPromptTemplate.format_prompt\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt.\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m text \u001b[38;5;241m=\u001b[39m format_text(text, input_formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_formatter)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ExtractionPromptValue(\n\u001b[1;32m---> 82\u001b[0m     string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_string(text), messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m )\n",
      "File \u001b[1;32m~\\OneDrive\\School\\lab\\Data Extraction from PDF\\code\\pdf-extraction\\venv2\\lib\\site-packages\\kor\\prompts.py:127\u001b[0m, in \u001b[0;36mExtractionPromptTemplate.to_messages\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example_input, example_output \u001b[38;5;129;01min\u001b[39;00m encoded_examples:\n\u001b[0;32m    120\u001b[0m     messages\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m    121\u001b[0m         [\n\u001b[0;32m    122\u001b[0m             HumanMessage(content\u001b[38;5;241m=\u001b[39mexample_input),\n\u001b[0;32m    123\u001b[0m             AIMessage(content\u001b[38;5;241m=\u001b[39mexample_output),\n\u001b[0;32m    124\u001b[0m         ]\n\u001b[0;32m    125\u001b[0m     )\n\u001b[1;32m--> 127\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m messages\n",
      "File \u001b[1;32m~\\OneDrive\\School\\lab\\Data Extraction from PDF\\code\\pdf-extraction\\venv2\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for HumanMessage\ncontent\n  str type expected (type=type_error.str)"
     ]
    }
   ],
   "source": [
    "print(chain.prompt.format_prompt(text=prompt_template).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "with get_openai_callback() as cb:\n",
    "    document_extraction_results = chain.predict_and_parse(text=(\"My name is Bobby. My brother's name Joe.\"))\n",
    "    print(f\"Output: {document_extraction_results}\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (pdf-extraction)",
   "language": "python",
   "name": "pycharm-aa15afaf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
